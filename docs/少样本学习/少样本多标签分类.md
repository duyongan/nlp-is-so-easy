# 利用元信息和对比学习解决零样本多标签分类问题

> 本篇为少样本多标签文本分类系列文章的第一篇



[TOC]



## 有监督多标签分类局限性

1. 人工标注价格昂贵且耗时长，特别是当标签空间很大的时候。
2. 只能处理训练集中出现的标签，一旦出现新的标签就得重新训练。
3. 倾向于训练集中频繁出现的标签，对于尾部标签效果不好。



## 推理阶段

1. 利用BM25进行标签召回，注意这里标签加入了标签描述。
2. 利用bert进行相似度重排序，计算文章和标签及描述之间的相关性。

![image-20221030134738537](https://notebook-media.oss-cn-beijing.aliyuncs.com/img/image-20221030134738537.png)



## 训练阶段

元信息：作者、地域、引用等，不同的场景可以有不同的元信息，本篇当中的数据集为论文。

利用元信息可以天然建立哪些文档更相近。

### 构建异构图

> 异构图：包含不同类型节点或边的图

1. PAP：paper–author–paper 同一个作者写的
2. PP：论文之间的引用
3. ……

![image-20221030134710897](https://notebook-media.oss-cn-beijing.aliyuncs.com/img/image-20221030134710897.png)

### 训练的架构

1. 分别在交互式和特征式两种进行实验，结果显示大部分情况下交互式效果更好
2. 利用对比学习，拉大正负样本的距离。例如下图中两篇文档有共同的两个作者比随机的更加相似。

<img src="https://notebook-media.oss-cn-beijing.aliyuncs.com/img/image-20221030135832041.png" alt="image-20221030135832041" style="zoom:67%;" />



### 损失函数

$$
- \log \frac { e x p ( \cos ( e _d , e _ { d^+ } ) / \tau ) } { e x p ( \cos ( e_d , e _ { d ^+} ) / \tau ) + \sum _ { i = 1 } ^ { N }e x p ( \cos ( e_d , e _ { d_i ^-} ) / \tau  }
$$



## 实验

![image-20221030140858713](https://notebook-media.oss-cn-beijing.aliyuncs.com/img/image-20221030140858713.png)



## 一点值得注意的地方

作者对元信息构建的不同路径进行了实验，发现叠加几条路径效果并没有得到显著提高，有些还是下降的。这也许是因为不同路径得出的结论是矛盾的。



![image-20221030141007460](https://notebook-media.oss-cn-beijing.aliyuncs.com/img/image-20221030141007460.png)



## 引用

1. （2022.3）Metadata-Induced Contrastive Learning for Zero-Shot Multi-Label Text Classification 

   ​					github:https://github.com/yuzhimanhua/MICoL



<font size=24>关注本公众号，下期更精彩</font>

<img src="https://notebook-media.oss-cn-beijing.aliyuncs.com/img/image-20220930221129484.png" alt="image-20220930221129484" style="zoom: 80%;" />



